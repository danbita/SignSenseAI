{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 11:01:19.292205: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (67208, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>file_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816796431</td>\n",
       "      <td>217</td>\n",
       "      <td>3 creekhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816825349</td>\n",
       "      <td>107</td>\n",
       "      <td>scales/kuhaylah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816909464</td>\n",
       "      <td>1</td>\n",
       "      <td>1383 william lanier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816967051</td>\n",
       "      <td>63</td>\n",
       "      <td>988 franklin lane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1817123330</td>\n",
       "      <td>89</td>\n",
       "      <td>6920 northeast 661st road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67203</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388192924</td>\n",
       "      <td>88</td>\n",
       "      <td>431-366-2913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67204</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388225542</td>\n",
       "      <td>154</td>\n",
       "      <td>994-392-3850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67205</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388232076</td>\n",
       "      <td>95</td>\n",
       "      <td>https://www.tianjiagenomes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67206</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388235284</td>\n",
       "      <td>36</td>\n",
       "      <td>90 kerwood circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67207</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388332538</td>\n",
       "      <td>176</td>\n",
       "      <td>802 co 66b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67208 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     path     file_id  sequence_id  \\\n",
       "0         train_landmarks/5414471.parquet     5414471   1816796431   \n",
       "1         train_landmarks/5414471.parquet     5414471   1816825349   \n",
       "2         train_landmarks/5414471.parquet     5414471   1816909464   \n",
       "3         train_landmarks/5414471.parquet     5414471   1816967051   \n",
       "4         train_landmarks/5414471.parquet     5414471   1817123330   \n",
       "...                                   ...         ...          ...   \n",
       "67203  train_landmarks/2118949241.parquet  2118949241    388192924   \n",
       "67204  train_landmarks/2118949241.parquet  2118949241    388225542   \n",
       "67205  train_landmarks/2118949241.parquet  2118949241    388232076   \n",
       "67206  train_landmarks/2118949241.parquet  2118949241    388235284   \n",
       "67207  train_landmarks/2118949241.parquet  2118949241    388332538   \n",
       "\n",
       "       participant_id                          phrase  \n",
       "0                 217                    3 creekhouse  \n",
       "1                 107                 scales/kuhaylah  \n",
       "2                   1             1383 william lanier  \n",
       "3                  63               988 franklin lane  \n",
       "4                  89       6920 northeast 661st road  \n",
       "...               ...                             ...  \n",
       "67203              88                    431-366-2913  \n",
       "67204             154                    994-392-3850  \n",
       "67205              95  https://www.tianjiagenomes.com  \n",
       "67206              36               90 kerwood circle  \n",
       "67207             176                      802 co 66b  \n",
       "\n",
       "[67208 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import mediapipe\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from skimage.transform import resize\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import animation, rc\n",
    "import Levenshtein as lev\n",
    "\n",
    "dataset_df = pd.read_csv('/data1/cosmos/Eric/kaggle/asl-fingerspelling/train.csv')\n",
    "print(\"Full train dataset shape is {}\".format(dataset_df.shape))\n",
    "\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_id: 1816796431, file_id: 5414471, phrase: 3 creekhouse\n",
      "Full sequence dataset shape is (123, 1630)\n"
     ]
    }
   ],
   "source": [
    "# Fetch sequence_id, file_id, phrase from first row\n",
    "sequence_id, file_id, phrase = dataset_df.iloc[0][['sequence_id', 'file_id', 'phrase']]\n",
    "print(f\"sequence_id: {sequence_id}, file_id: {file_id}, phrase: {phrase}\")\n",
    "\n",
    "# Fetch data from parquet file\n",
    "sample_sequence_df = pq.read_table(f\"/data1/cosmos/Eric/kaggle/asl-fingerspelling/train_landmarks/{str(file_id)}.parquet\",\n",
    "    filters=[[('sequence_id', '=', sequence_id)],]).to_pandas()\n",
    "print(\"Full sequence dataset shape is {}\".format(sample_sequence_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/matplotlib/animation.py:884: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Function create animation from images.\n",
    "\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "matplotlib.rcParams['savefig.pad_inches'] = 0\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "def create_animation(images):\n",
    "    fig = plt.figure(figsize=(6, 9))\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    im=ax.imshow(images[0], cmap=\"Blues\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    def animate_func(i):\n",
    "        im.set_array(images[i])\n",
    "        return [im]\n",
    "\n",
    "    return animation.FuncAnimation(fig, animate_func, frames=len(images), interval=1000/10)\n",
    "\n",
    "# Extract the landmark data and convert it to an image using medipipe library.\n",
    "# This function extracts the data for both hands.\n",
    "\n",
    "mp_pose = mediapipe.solutions.pose\n",
    "mp_hands = mediapipe.solutions.hands\n",
    "mp_drawing = mediapipe.solutions.drawing_utils\n",
    "mp_drawing_styles = mediapipe.solutions.drawing_styles\n",
    "\n",
    "def get_hands(seq_df):\n",
    "    images = []\n",
    "    all_hand_landmarks = []\n",
    "    for seq_idx in range(len(seq_df)):\n",
    "        x_hand = seq_df.iloc[seq_idx].filter(regex=\"x_right_hand.*\").values\n",
    "        y_hand = seq_df.iloc[seq_idx].filter(regex=\"y_right_hand.*\").values\n",
    "        z_hand = seq_df.iloc[seq_idx].filter(regex=\"z_right_hand.*\").values\n",
    "\n",
    "        right_hand_image = np.zeros((600, 600, 3))\n",
    "\n",
    "        right_hand_landmarks = landmark_pb2.NormalizedLandmarkList()\n",
    "\n",
    "        for x, y, z in zip(x_hand, y_hand, z_hand):\n",
    "            right_hand_landmarks.landmark.add(x=x, y=y, z=z)\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "                right_hand_image,\n",
    "                right_hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style())\n",
    "\n",
    "        x_hand = seq_df.iloc[seq_idx].filter(regex=\"x_left_hand.*\").values\n",
    "        y_hand = seq_df.iloc[seq_idx].filter(regex=\"y_left_hand.*\").values\n",
    "        z_hand = seq_df.iloc[seq_idx].filter(regex=\"z_left_hand.*\").values\n",
    "\n",
    "        left_hand_image = np.zeros((600, 600, 3))\n",
    "\n",
    "        left_hand_landmarks = landmark_pb2.NormalizedLandmarkList()\n",
    "        for x, y, z in zip(x_hand, y_hand, z_hand):\n",
    "            left_hand_landmarks.landmark.add(x=x, y=y, z=z)\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "                left_hand_image,\n",
    "                left_hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style())\n",
    "\n",
    "        images.append([right_hand_image.astype(np.uint8), left_hand_image.astype(np.uint8)])\n",
    "        all_hand_landmarks.append([right_hand_landmarks, left_hand_landmarks])\n",
    "    return images, all_hand_landmarks\n",
    "\n",
    "# Get the images created using mediapipe apis\n",
    "hand_images, hand_landmarks = get_hands(sample_sequence_df)\n",
    "# Fetch and show the data for right hand\n",
    "create_animation(np.array(hand_images)[:len(hand_images), 0])\n",
    "\n",
    "# Pose coordinates for hand movement.\n",
    "LPOSE = [13, 15, 17, 19, 21]\n",
    "RPOSE = [14, 16, 18, 20, 22]\n",
    "POSE = LPOSE + RPOSE\n",
    "\n",
    "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
    "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
    "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
    "\n",
    "FEATURE_COLUMNS = X + Y + Z\n",
    "\n",
    "X_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if \"x_\" in col]\n",
    "Y_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if \"y_\" in col]\n",
    "Z_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if \"z_\" in col]\n",
    "\n",
    "RHAND_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if \"right\" in col]\n",
    "LHAND_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if  \"left\" in col]\n",
    "RPOSE_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
    "LPOSE_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
    "\n",
    "# Set length of frames to 128\n",
    "FRAME_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2fd98047304a8f8d04cda101d3ac41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create directory to store the new data\n",
    "if not os.path.isdir(\"preprocessed\"):\n",
    "    os.mkdir(\"preprocessed\")\n",
    "else:\n",
    "    shutil.rmtree(\"preprocessed\")\n",
    "    os.mkdir(\"preprocessed\")\n",
    "\n",
    "# Loop through each file_id\n",
    "    # Parquet file name\n",
    "for file_id in tqdm(dataset_df.file_id.unique()):\n",
    "    pq_file = f\"/data1/cosmos/Eric/kaggle/asl-fingerspelling/train_landmarks/{str(file_id)}.parquet\"\n",
    "    # Filter train.csv and fetch entries only for the relevant file_id\n",
    "    file_df = dataset_df.loc[dataset_df[\"file_id\"] == file_id]\n",
    "    # Fetch the parquet file\n",
    "    parquet_df = pq.read_table(f\"/data1/cosmos/Eric/kaggle/asl-fingerspelling/train_landmarks/{str(file_id)}.parquet\",\n",
    "                              columns=['sequence_id'] + FEATURE_COLUMNS).to_pandas()\n",
    "    # File name for the updated data\n",
    "    tf_file = f\"preprocessed/{file_id}.tfrecord\"\n",
    "    parquet_numpy = parquet_df.to_numpy()\n",
    "    # Initialize the pointer to write the output of\n",
    "    # each `for loop` below as a sequence into the file.\n",
    "    with tf.io.TFRecordWriter(tf_file) as file_writer:\n",
    "        # Loop through each sequence in file.\n",
    "        for seq_id, phrase in zip(file_df.sequence_id, file_df.phrase):\n",
    "            # Fetch sequence data\n",
    "            frames = parquet_numpy[parquet_df.index == seq_id]\n",
    "\n",
    "            # Calculate the number of NaN values in each hand landmark\n",
    "            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n",
    "            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n",
    "            no_nan = max(r_nonan, l_nonan)\n",
    "\n",
    "            if 2*len(phrase)<no_nan:\n",
    "                features = {FEATURE_COLUMNS[i]: tf.train.Feature(\n",
    "                    float_list=tf.train.FloatList(value=frames[:, i])) for i in range(len(FEATURE_COLUMNS))}\n",
    "                features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(phrase, 'utf-8')]))\n",
    "                record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n",
    "                file_writer.write(record_bytes)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 68 TFRecord files.\n"
     ]
    }
   ],
   "source": [
    "tf_records = dataset_df.file_id.map(lambda x: f'/data1/cosmos/Eric/kaggle/preprocessed/{x}.tfrecord').unique()\n",
    "print(f\"List of {len(tf_records)} TFRecord files.\")\n",
    "\n",
    "with open (\"/data1/cosmos/Eric/kaggle/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
    "    char_to_num = json.load(f)\n",
    "\n",
    "# Add pad_token, start pointer and end pointer to the dict\n",
    "pad_token = 'P'\n",
    "start_token = '<'\n",
    "end_token = '>'\n",
    "pad_token_idx = 59\n",
    "start_token_idx = 60\n",
    "end_token_idx = 61\n",
    "\n",
    "char_to_num[pad_token] = pad_token_idx\n",
    "char_to_num[start_token] = start_token_idx\n",
    "char_to_num[end_token] = end_token_idx\n",
    "num_to_char = {j:i for i,j in char_to_num.items()}\n",
    "\n",
    "# Reference: https://www.kaggle.com/code/irohith/aslfr-transformer/notebook\n",
    "\n",
    "# Function to resize and add padding.\n",
    "def resize_pad(x):\n",
    "    if tf.shape(x)[0] < FRAME_LEN:\n",
    "        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]))\n",
    "    else:\n",
    "        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Detect the dominant hand from the number of NaN values.\n",
    "# Dominant hand will have less NaN values since it is in frame moving.\n",
    "def pre_process(x):\n",
    "    rhand = tf.gather(x, RHAND_IDX, axis=1)\n",
    "    lhand = tf.gather(x, LHAND_IDX, axis=1)\n",
    "    rpose = tf.gather(x, RPOSE_IDX, axis=1)\n",
    "    lpose = tf.gather(x, LPOSE_IDX, axis=1)\n",
    "\n",
    "    rnan_idx = tf.reduce_any(tf.math.is_nan(rhand), axis=1)\n",
    "    lnan_idx = tf.reduce_any(tf.math.is_nan(lhand), axis=1)\n",
    "\n",
    "    rnans = tf.math.count_nonzero(rnan_idx)\n",
    "    lnans = tf.math.count_nonzero(lnan_idx)\n",
    "\n",
    "    # For dominant hand\n",
    "    if rnans > lnans:\n",
    "        hand = lhand\n",
    "        pose = lpose\n",
    "\n",
    "        hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
    "        hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
    "        hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
    "        hand = tf.concat([1-hand_x, hand_y, hand_z], axis=1)\n",
    "\n",
    "        pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
    "        pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
    "        pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
    "        pose = tf.concat([1-pose_x, pose_y, pose_z], axis=1)\n",
    "    else:\n",
    "        hand = rhand\n",
    "        pose = rpose\n",
    "\n",
    "    hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
    "    hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
    "    hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
    "    hand = tf.concat([hand_x[..., tf.newaxis], hand_y[..., tf.newaxis], hand_z[..., tf.newaxis]], axis=-1)\n",
    "\n",
    "    mean = tf.math.reduce_mean(hand, axis=1)[:, tf.newaxis, :]\n",
    "    std = tf.math.reduce_std(hand, axis=1)[:, tf.newaxis, :]\n",
    "    hand = (hand - mean) / std\n",
    "\n",
    "    pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
    "    pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
    "    pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
    "    pose = tf.concat([pose_x[..., tf.newaxis], pose_y[..., tf.newaxis], pose_z[..., tf.newaxis]], axis=-1)\n",
    "\n",
    "    x = tf.concat([hand, pose], axis=1)\n",
    "    x = resize_pad(x)\n",
    "\n",
    "    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
    "    x = tf.reshape(x, (FRAME_LEN, len(LHAND_IDX) + len(LPOSE_IDX)))\n",
    "    return x\n",
    "\n",
    "def decode_fn(record_bytes):\n",
    "    schema = {COL: tf.io.VarLenFeature(dtype=tf.float32) for COL in FEATURE_COLUMNS}\n",
    "    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "    features = tf.io.parse_single_example(record_bytes, schema)\n",
    "    phrase = features[\"phrase\"]\n",
    "    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in FEATURE_COLUMNS])\n",
    "    # Transpose to maintain the original shape of landmarks data.\n",
    "    landmarks = tf.transpose(landmarks)\n",
    "\n",
    "    return landmarks, phrase\n",
    "\n",
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=list(char_to_num.keys()),\n",
    "        values=list(char_to_num.values()),\n",
    "    ),\n",
    "    default_value=tf.constant(-1),\n",
    "    name=\"class_weight\"\n",
    ")\n",
    "\n",
    "def convert_fn(landmarks, phrase):\n",
    "    # Add start and end pointers to phrase.\n",
    "    phrase = start_token + phrase + end_token\n",
    "    phrase = tf.strings.bytes_split(phrase)\n",
    "    phrase = table.lookup(phrase)\n",
    "    # Vectorize and add padding.\n",
    "    phrase = tf.pad(phrase, paddings=[[0, 64 - tf.shape(phrase)[0]]], mode = 'CONSTANT',\n",
    "                    constant_values = pad_token_idx)\n",
    "    # Apply pre_process function to the landmarks.\n",
    "    return pre_process(landmarks), phrase\n",
    "\n",
    "batch_size = 32\n",
    "train_len = int(0.8 * len(tf_records))\n",
    "valid_len = int(0.1 * len(tf_records))\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(tf_records[1:train_len]).map(decode_fn).map(convert_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "valid_ds = tf.data.TFRecordDataset(tf_records[train_len:train_len+valid_len]).map(decode_fn).map(convert_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "test_ds = tf.data.TFRecordDataset(tf_records[train_len+valid_len:]).map(decode_fn).map(convert_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 11:18:58.549940: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x)\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "class LandmarkEmbedding(layers.Layer):\n",
    "    def __init__(self, num_hid=64, maxlen=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.conv3(x)\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# Customized to add `training` variable\n",
    "# Reference: https://www.kaggle.com/code/shlomoron/aslfr-a-simple-transformer/notebook\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.self_att = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.self_dropout = layers.Dropout(0.5)\n",
    "        self.enc_dropout = layers.Dropout(0.1)\n",
    "        self.ffn_dropout = layers.Dropout(0.1)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "\n",
    "        This prevents flow of information from future tokens to current token.\n",
    "        1's in the lower triangle, counting from the lower right corner.\n",
    "        \"\"\"\n",
    "        i = tf.range(n_dest)[:, None]\n",
    "        j = tf.range(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = tf.cast(m, dtype)\n",
    "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "        mult = tf.concat(\n",
    "            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, enc_out, target, training):\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
    "        target_norm = self.layernorm1(target + self.self_dropout(target_att, training = training))\n",
    "        enc_out = self.enc_att(target_norm, enc_out)\n",
    "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out, training = training) + target_norm)\n",
    "        ffn_out = self.ffn(enc_out_norm)\n",
    "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out, training = training))\n",
    "        return ffn_out_norm\n",
    "\n",
    "# Customized to add edit_dist metric and training variable.\n",
    "# Reference:\n",
    "# https://www.kaggle.com/code/irohith/aslfr-transformer/notebook\n",
    "# https://www.kaggle.com/code/shlomoron/aslfr-a-simple-transformer/notebook\n",
    "\n",
    "class Transformer(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hid=64,\n",
    "        num_head=2,\n",
    "        num_feed_forward=128,\n",
    "        source_maxlen=100,\n",
    "        target_maxlen=100,\n",
    "        num_layers_enc=4,\n",
    "        num_layers_dec=1,\n",
    "        num_classes=60,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
    "        self.acc_metric = keras.metrics.Mean(name=\"edit_dist\")\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.target_maxlen = target_maxlen\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc_input = LandmarkEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
    "        self.dec_input = TokenEmbedding(\n",
    "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
    "        )\n",
    "\n",
    "        self.encoder = keras.Sequential(\n",
    "            [self.enc_input]\n",
    "            + [\n",
    "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
    "                for _ in range(num_layers_enc)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers_dec):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"dec_layer_{i}\",\n",
    "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
    "            )\n",
    "\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def decode(self, enc_out, target, training):\n",
    "        y = self.dec_input(target)\n",
    "        for i in range(self.num_layers_dec):\n",
    "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y, training)\n",
    "        return y\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        source = inputs[0]\n",
    "        target = inputs[1]\n",
    "        x = self.encoder(source, training)\n",
    "        y = self.decode(x, target, training)\n",
    "        return self.classifier(y)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
    "        source = batch[0]\n",
    "        target = batch[1]\n",
    "\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self([source, dec_input])\n",
    "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "            mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
    "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Computes the Levenshtein distance between sequences since the evaluation\n",
    "        # metric for this contest is the normalized total levenshtein distance.\n",
    "        edit_dist = tf.edit_distance(tf.sparse.from_dense(target),\n",
    "                                     tf.sparse.from_dense(tf.cast(tf.argmax(preds, axis=1), tf.int32)))\n",
    "        edit_dist = tf.reduce_mean(edit_dist)\n",
    "        self.acc_metric.update_state(edit_dist)\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result(), \"edit_dist\": self.acc_metric.result()}\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        source = batch[0]\n",
    "        target = batch[1]\n",
    "\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        preds = self([source, dec_input])\n",
    "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "        mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
    "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
    "        # Computes the Levenshtein distance between sequences since the evaluation\n",
    "        # metric for this contest is the normalized total levenshtein distance.\n",
    "        edit_dist = tf.edit_distance(tf.sparse.from_dense(target),\n",
    "                                     tf.sparse.from_dense(tf.cast(tf.argmax(preds, axis=1), tf.int32)))\n",
    "        edit_dist = tf.reduce_mean(edit_dist)\n",
    "        self.acc_metric.update_state(edit_dist)\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result(), \"edit_dist\": self.acc_metric.result()}\n",
    "\n",
    "    def generate(self, source, target_start_token_idx):\n",
    "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
    "        bs = tf.shape(source)[0]\n",
    "        enc = self.encoder(source, training = False)\n",
    "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
    "        dec_logits = []\n",
    "        for i in range(self.target_maxlen - 1):\n",
    "            dec_out = self.decode(enc, dec_input, training = False)\n",
    "            logits = self.classifier(dec_out)\n",
    "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            last_logit = logits[:, -1][..., tf.newaxis]\n",
    "            dec_logits.append(last_logit)\n",
    "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
    "        return dec_input\n",
    "\n",
    "class DisplayOutputs(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self, batch, idx_to_token, target_start_token_idx=60, target_end_token_idx=61\n",
    "    ):\n",
    "        \"\"\"Displays a batch of outputs after every 4 epoch\n",
    "\n",
    "        Args:\n",
    "            batch: A test batch\n",
    "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
    "            target_start_token_idx: A start token index in the target vocabulary\n",
    "            target_end_token_idx: An end token index in the target vocabulary\n",
    "        \"\"\"\n",
    "        self.batch = batch\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 4 != 0:\n",
    "            return\n",
    "        source = self.batch[0]\n",
    "        target = self.batch[1].numpy()\n",
    "        bs = tf.shape(source)[0]\n",
    "        preds = self.model.generate(source, self.target_start_token_idx)\n",
    "        preds = preds.numpy()\n",
    "        for i in range(bs):\n",
    "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
    "            prediction = \"\"\n",
    "            for idx in preds[i, :]:\n",
    "                prediction += self.idx_to_char[idx]\n",
    "                if idx == self.target_end_token_idx:\n",
    "                    break\n",
    "            print(f\"target:     {target_text.replace('-','')}\")\n",
    "            print(f\"prediction: {prediction}\\n\")\n",
    "\n",
    "# Transformer variables are customized from original keras tutorial to suit this dataset.\n",
    "# Reference: https://www.kaggle.com/code/shlomoron/aslfr-a-simple-transformer/notebook\n",
    "\n",
    "batch = next(iter(train_ds))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vocabulary to convert predicted indices into characters\n",
    "idx_to_char = list(char_to_num.keys())\n",
    "display_cb = DisplayOutputs(\n",
    "    batch, idx_to_char, target_start_token_idx=char_to_num['<'], target_end_token_idx=char_to_num['>']\n",
    ")  # set the arguments as per vocabulary index for '<' and '>'\n",
    "\n",
    "model = Transformer(\n",
    "    num_hid=600,\n",
    "    num_head=4,\n",
    "    num_feed_forward=3200,\n",
    "    source_maxlen = FRAME_LEN,\n",
    "    target_maxlen=64,\n",
    "    num_layers_enc=1,\n",
    "    num_layers_dec=1,\n",
    "    num_classes=62\n",
    ")\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, label_smoothing=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(0.0001)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "   1240/Unknown - 66s 51ms/step - loss: 0.7774 - edit_dist: 1.0781target:     <2398 masonic parks road>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <398 asenid arad>\n",
      "\n",
      "target:     <+34637492>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+35-663-63-92-92>\n",
      "\n",
      "target:     <tpmazembe/artist/kousek.lasky>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <https://kewatitititit.alala>\n",
      "\n",
      "target:     <540 south 310th place>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <47 soo d 1119>\n",
      "\n",
      "target:     <+485894958>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+50-898-4988>\n",
      "\n",
      "target:     <jovan austin>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <jondan sti>\n",
      "\n",
      "target:     <www.azcalphen.nl/motercycle/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.stallere.comercom>\n",
      "\n",
      "target:     <+855337916074>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+95-370-0916-074>\n",
      "\n",
      "target:     <practicarmatcha>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <aracati male chal cha>\n",
      "\n",
      "target:     </cordes1344>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: </codas-11334>\n",
      "\n",
      "target:     <valdy.ru/menguinacquired/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <malaran cke ckerond>\n",
      "\n",
      "target:     <2974 scotty carson>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <2974 sotica caroad>\n",
      "\n",
      "target:     <portofinoresidence>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <109 sid veree>\n",
      "\n",
      "target:     <www.etablisainteanne.com>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.malicies.com.com>\n",
      "\n",
      "target:     <www.devionhinton.com/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.briesten.com>\n",
      "\n",
      "target:     <tomveitch>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <tompo-tererere>\n",
      "\n",
      "target:     <857 baurkot drive>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <8874 cart rine>\n",
      "\n",
      "target:     <521 southeast 177th avenue>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <5217 southeast 17t 17tree>\n",
      "\n",
      "target:     <965860 leisore>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <9658 pey sie>\n",
      "\n",
      "target:     <lokerciamis.my.id/citymate235>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <dercailimiti.com.com.com.om/>\n",
      "\n",
      "target:     <kevin hurley>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <ntthan daney>\n",
      "\n",
      "target:     <531859 arkhaven road>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <5189 arth 20th 20t>\n",
      "\n",
      "target:     <laciudad>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <11 cive trtrd>\n",
      "\n",
      "target:     <163263 fort ritchie access>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <2323 forthithices>\n",
      "\n",
      "target:     <6008166767>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <600-756-5656>\n",
      "\n",
      "target:     <www.communechihia.gov.tn>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <6915 sel hay hoand>\n",
      "\n",
      "target:     <https://www.casa.org.ar>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.salas.com/>\n",
      "\n",
      "target:     <jermaine raymond>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <jerman derl>\n",
      "\n",
      "target:     <793 mooreshill>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <793 more hil>\n",
      "\n",
      "target:     <2714661311>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <270-466-4611>\n",
      "\n",
      "target:     <9265 dobeckmun avenue>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <9650 co mnntrntroaronue>\n",
      "\n",
      "target:     <2859 mcgillicuddy>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <189 mco chilli>\n",
      "\n",
      "1240/1240 [==============================] - 76s 60ms/step - loss: 0.7774 - edit_dist: 1.0781 - val_loss: 0.6739 - val_edit_dist: 1.0726\n",
      "Epoch 2/15\n",
      "1240/1240 [==============================] - 33s 27ms/step - loss: 0.6028 - edit_dist: 1.0674 - val_loss: 0.5696 - val_edit_dist: 1.0619\n",
      "Epoch 3/15\n",
      "1240/1240 [==============================] - 33s 27ms/step - loss: 0.5179 - edit_dist: 1.0582 - val_loss: 0.5275 - val_edit_dist: 1.0543\n",
      "Epoch 4/15\n",
      "1240/1240 [==============================] - 33s 27ms/step - loss: 0.4683 - edit_dist: 1.0520 - val_loss: 0.5221 - val_edit_dist: 1.0495\n",
      "Epoch 5/15\n",
      "1239/1240 [============================>.] - ETA: 0s - loss: 0.4340 - edit_dist: 1.0477target:     <2398 masonic parks road>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <398 masoni passoni road>\n",
      "\n",
      "target:     <+34637492>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+34-63-744-92>\n",
      "\n",
      "target:     <tpmazembe/artist/kousek.lasky>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <thmatemb/artemb/artek-iskaky>\n",
      "\n",
      "target:     <540 south 310th place>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+44-00002-23-10-509>\n",
      "\n",
      "target:     <+485894958>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+48-89-4958>\n",
      "\n",
      "target:     <jovan austin>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <jorn hasti>\n",
      "\n",
      "target:     <www.azcalphen.nl/motercycle/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.sto-shundare.com/kercle>\n",
      "\n",
      "target:     <+855337916074>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+955-337-916-074>\n",
      "\n",
      "target:     <practicarmatcha>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <ractite martt matchas>\n",
      "\n",
      "target:     </cordes1344>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: </coudendernes/1334>\n",
      "\n",
      "target:     <valdy.ru/menguinacquired/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <malia-uia-tur/menthou/>\n",
      "\n",
      "target:     <2974 scotty carson>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <2974 scoty carrs>\n",
      "\n",
      "target:     <portofinoresidence>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <rtofnno-trusiden.com>\n",
      "\n",
      "target:     <www.etablisainteanne.com>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.esablissintee.com>\n",
      "\n",
      "target:     <www.devionhinton.com/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.buisourtseran.com/>\n",
      "\n",
      "target:     <tomveitch>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <tomps svenito>\n",
      "\n",
      "target:     <857 baurkot drive>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <85724 bourt prine>\n",
      "\n",
      "target:     <521 southeast 177th avenue>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <521 southeast 17th 20treet>\n",
      "\n",
      "target:     <965860 leisore>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <9658 watlei ple>\n",
      "\n",
      "target:     <lokerciamis.my.id/citymate235>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <tokercamis-my-ititi-itima-e223>\n",
      "\n",
      "target:     <kevin hurley>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <nanton parley>\n",
      "\n",
      "target:     <531859 arkhaven road>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <511859 farr 2070>\n",
      "\n",
      "target:     <laciudad>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <lattcevkad>\n",
      "\n",
      "target:     <163263 fort ritchie access>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <1232 forth fort ritces>\n",
      "\n",
      "target:     <6008166767>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <600-816-7816>\n",
      "\n",
      "target:     <www.communechihia.gov.tn>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <4315 avens house hourt>\n",
      "\n",
      "target:     <https://www.casa.org.ar>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <2332 wast st st street>\n",
      "\n",
      "target:     <jermaine raymond>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <jermaine raimer dr>\n",
      "\n",
      "target:     <793 mooreshill>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <793 noreshill>\n",
      "\n",
      "target:     <2714661311>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <277-466-1111>\n",
      "\n",
      "target:     <9265 dobeckmun avenue>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <9265 dobeckmna cavenue>\n",
      "\n",
      "target:     <2859 mcgillicuddy>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <189 mcoc gili crrdy>\n",
      "\n",
      "1240/1240 [==============================] - 33s 26ms/step - loss: 0.4339 - edit_dist: 1.0477 - val_loss: 0.5308 - val_edit_dist: 1.0458\n",
      "Epoch 6/15\n",
      "1240/1240 [==============================] - 32s 26ms/step - loss: 0.4072 - edit_dist: 1.0444 - val_loss: 0.5330 - val_edit_dist: 1.0430\n",
      "Epoch 7/15\n",
      "1240/1240 [==============================] - 34s 27ms/step - loss: 0.3834 - edit_dist: 1.0420 - val_loss: 0.5410 - val_edit_dist: 1.0408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "1240/1240 [==============================] - 33s 27ms/step - loss: 0.3631 - edit_dist: 1.0400 - val_loss: 0.5509 - val_edit_dist: 1.0390\n",
      "Epoch 9/15\n",
      "1239/1240 [============================>.] - ETA: 0s - loss: 0.3453 - edit_dist: 1.0384target:     <2398 masonic parks road>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <398 massoni parks road>\n",
      "\n",
      "target:     <+34637492>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <134-631-9219>\n",
      "\n",
      "target:     <tpmazembe/artist/kousek.lasky>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <thmatembe/artemb/arsek-laky>\n",
      "\n",
      "target:     <540 south 310th place>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <5410 south 310th place>\n",
      "\n",
      "target:     <+485894958>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+48-89-4958>\n",
      "\n",
      "target:     <jovan austin>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <jownn gresti>\n",
      "\n",
      "target:     <www.azcalphen.nl/motercycle/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.xzh.tm.twor.com>\n",
      "\n",
      "target:     <+855337916074>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+85-337-916-074>\n",
      "\n",
      "target:     <practicarmatcha>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <racticar.matcha>\n",
      "\n",
      "target:     </cordes1344>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: </conderssl34>\n",
      "\n",
      "target:     <valdy.ru/menguinacquired/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <mvalia.rumenthin.cor/>\n",
      "\n",
      "target:     <2974 scotty carson>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <2974 scoty carrs>\n",
      "\n",
      "target:     <portofinoresidence>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <prtofind-rusiden.ce>\n",
      "\n",
      "target:     <www.etablisainteanne.com>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.ellissain-ekake.com>\n",
      "\n",
      "target:     <www.devionhinton.com/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.brioses.com/>\n",
      "\n",
      "target:     <tomveitch>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <mpstueni chres>\n",
      "\n",
      "target:     <857 baurkot drive>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <158574 barrok prive>\n",
      "\n",
      "target:     <521 southeast 177th avenue>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <521 southeast 17th ave street>\n",
      "\n",
      "target:     <965860 leisore>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <9658 watt eill place>\n",
      "\n",
      "target:     <lokerciamis.my.id/citymate235>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <lekerciamis.myalitite235>\n",
      "\n",
      "target:     <kevin hurley>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <kenndan blings>\n",
      "\n",
      "target:     <531859 arkhaven road>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <5188 farm hough 26526 road>\n",
      "\n",
      "target:     <laciudad>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <lazececiudad>\n",
      "\n",
      "target:     <163263 fort ritchie access>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <1632 fortrit hiea aces>\n",
      "\n",
      "target:     <6008166767>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <600-816-8167>\n",
      "\n",
      "target:     <www.communechihia.gov.tn>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <41 ncree.bl/hampez>\n",
      "\n",
      "target:     <https://www.casa.org.ar>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <668 west stast 107th>\n",
      "\n",
      "target:     <jermaine raymond>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <jerm aine raimond>\n",
      "\n",
      "target:     <793 mooreshill>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <793 moreshil>\n",
      "\n",
      "target:     <2714661311>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <271-466-2110>\n",
      "\n",
      "target:     <9265 dobeckmun avenue>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <9668 dobeckmnnan cavenue>\n",
      "\n",
      "target:     <2859 mcgillicuddy>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <289 mcgilicr rdy>\n",
      "\n",
      "1240/1240 [==============================] - 33s 27ms/step - loss: 0.3453 - edit_dist: 1.0384 - val_loss: 0.5641 - val_edit_dist: 1.0376\n",
      "Epoch 10/15\n",
      "1240/1240 [==============================] - 32s 26ms/step - loss: 0.3287 - edit_dist: 1.0370 - val_loss: 0.5695 - val_edit_dist: 1.0363\n",
      "Epoch 11/15\n",
      "1240/1240 [==============================] - 33s 27ms/step - loss: 0.3142 - edit_dist: 1.0358 - val_loss: 0.5785 - val_edit_dist: 1.0352\n",
      "Epoch 12/15\n",
      "1240/1240 [==============================] - 34s 27ms/step - loss: 0.3020 - edit_dist: 1.0348 - val_loss: 0.5838 - val_edit_dist: 1.0344\n",
      "Epoch 13/15\n",
      "1238/1240 [============================>.] - ETA: 0s - loss: 0.2930 - edit_dist: 1.0340target:     <2398 masonic parks road>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <2398 massoni parks road>\n",
      "\n",
      "target:     <+34637492>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+34-784-92>\n",
      "\n",
      "target:     <tpmazembe/artist/kousek.lasky>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <thmaze.combe/artek-laky>\n",
      "\n",
      "target:     <540 south 310th place>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <540 outh 210th place>\n",
      "\n",
      "target:     <+485894958>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+204-89-4958>\n",
      "\n",
      "target:     <jovan austin>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <jorona tursti>\n",
      "\n",
      "target:     <www.azcalphen.nl/motercycle/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.xzzzzzous.cz/10350>\n",
      "\n",
      "target:     <+855337916074>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+95-337-916-074>\n",
      "\n",
      "target:     <practicarmatcha>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <ractiear matcha>\n",
      "\n",
      "target:     </cordes1344>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: </conduperss-1344>\n",
      "\n",
      "target:     <valdy.ru/menguinacquired/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <mvalia.ru/menguedu/>\n",
      "\n",
      "target:     <2974 scotty carson>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <2974 scotty car rs>\n",
      "\n",
      "target:     <portofinoresidence>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <prtofin orsidnce>\n",
      "\n",
      "target:     <www.etablisainteanne.com>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.eeladin-ekne.com>\n",
      "\n",
      "target:     <www.devionhinton.com/>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <www.briosservios.com/>\n",
      "\n",
      "target:     <tomveitch>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <tueni c>\n",
      "\n",
      "target:     <857 baurkot drive>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <857 bardon drive>\n",
      "\n",
      "target:     <521 southeast 177th avenue>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <521 southeast 170th avenue>\n",
      "\n",
      "target:     <965860 leisore>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <9658 watt eichat exd>\n",
      "\n",
      "target:     <lokerciamis.my.id/citymate235>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <lokokouciamis.ydu/jimate25>\n",
      "\n",
      "target:     <kevin hurley>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <ennnd parville>\n",
      "\n",
      "target:     <531859 arkhaven road>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <5189 farm hkver road>\n",
      "\n",
      "target:     <laciudad>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <lazecece jukad>\n",
      "\n",
      "target:     <163263 fort ritchie access>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <123223 fortuit hie aces>\n",
      "\n",
      "target:     <6008166767>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <+60-816-816-816-8367>\n",
      "\n",
      "target:     <www.communechihia.gov.tn>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <2915 akends forend>\n",
      "\n",
      "target:     <https://www.casa.org.ar>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <2326 sant wholand>\n",
      "\n",
      "target:     <jermaine raymond>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <jerm aine raymond>\n",
      "\n",
      "target:     <793 mooreshill>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <7930 doreshil>\n",
      "\n",
      "target:     <2714661311>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <270-466-2110>\n",
      "\n",
      "target:     <9265 dobeckmun avenue>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <9268 dobeckmonnt cavenue>\n",
      "\n",
      "target:     <2859 mcgillicuddy>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
      "prediction: <289 mcgili crdy>\n",
      "\n",
      "1240/1240 [==============================] - 34s 28ms/step - loss: 0.2930 - edit_dist: 1.0340 - val_loss: 0.5897 - val_edit_dist: 1.0335\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240/1240 [==============================] - 33s 27ms/step - loss: 0.2842 - edit_dist: 1.0331 - val_loss: 0.5920 - val_edit_dist: 1.0327\n",
      "Epoch 15/15\n",
      "1240/1240 [==============================] - 33s 27ms/step - loss: 0.2780 - edit_dist: 1.0323 - val_loss: 0.5959 - val_edit_dist: 1.0319\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=valid_ds, callbacks=[display_cb], epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_inputs:0', 'index': 0, 'shape': array([  1, 156], dtype=int32), 'shape_signature': array([ -1, 156], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details: [{'name': 'StatefulPartitionedCall:0', 'index': 10456, 'shape': array([ 1, 59], dtype=int32), 'shape_signature': array([-1, 59], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Replace 'path/to/your_model.tflite' with the actual path to your TFLite model file.\n",
    "model_path = '/data1/cosmos/Eric/kaggle/model.tflite'\n",
    "\n",
    "# Initialize the TensorFlow Lite interpreter.\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "\n",
    "# Allocate memory for the model.\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details (optional but can be useful).\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Input details provide information about the input tensor(s).\n",
    "print(\"Input details:\", input_details)\n",
    "\n",
    "# Output details provide information about the output tensor(s).\n",
    "print(\"Output details:\", output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.embedding.Embedding object at 0x7fe228bd1a60>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv1d_6_layer_call_fn, conv1d_6_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv1d_7_layer_call_fn, conv1d_7_layer_call_and_return_conditional_losses while saving (showing 5 of 75). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpumua5me9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpumua5me9/assets\n",
      "2023-07-28 11:38:19.061620: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-07-28 11:38:19.061651: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-07-28 11:38:19.062225: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpumua5me9\n",
      "2023-07-28 11:38:19.085260: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2023-07-28 11:38:19.085285: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: /tmp/tmpumua5me9\n",
      "2023-07-28 11:38:19.180812: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-07-28 11:38:19.210033: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-28 11:38:20.441918: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpumua5me9\n",
      "2023-07-28 11:38:21.394756: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2332534 microseconds.\n",
      "2023-07-28 11:38:22.461176: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    " class TFLiteModel(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "        self.target_start_token_idx = start_token_idx\n",
    "        self.target_end_token_idx = end_token_idx\n",
    "        # Load the feature generation and main models\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(FEATURE_COLUMNS)], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs, training=False):\n",
    "        # Preprocess Data\n",
    "        x = tf.cast(inputs, tf.float32)\n",
    "        x = x[None]\n",
    "        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, len(FEATURE_COLUMNS))), lambda: tf.identity(x))\n",
    "        x = x[0]\n",
    "        x = pre_process(x)\n",
    "        x = x[None]\n",
    "        x = self.model.generate(x, self.target_start_token_idx)\n",
    "        x = x[0]\n",
    "        idx = tf.argmax(tf.cast(tf.equal(x, self.target_end_token_idx), tf.int32))\n",
    "        idx = tf.where(tf.math.less(idx, 1), tf.constant(2, dtype=tf.int64), idx)\n",
    "        x = x[1:idx]\n",
    "        x = tf.one_hot(x, 59)\n",
    "        return {'outputs': x}\n",
    "    \n",
    "tflitemodel_base = TFLiteModel(model)\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "\n",
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\n",
    "keras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = keras_model_converter.convert()\n",
    "with open('/data1/cosmos/Eric/kaggle/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    \n",
    "infargs = {\"selected_columns\" : FEATURE_COLUMNS}\n",
    "\n",
    "with open('inference_args.json', \"w\") as json_file:\n",
    "    json.dump(infargs, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /usr/local/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "  adding: model.tflite (deflated 19%)\n",
      "  adding: inference_args.json (deflated 85%)\n"
     ]
    }
   ],
   "source": [
    "!zip submission.zip  './model.tflite' './inference_args.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.progs.com/\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
    "\n",
    "REQUIRED_SIGNATURE = \"serving_default\"\n",
    "REQUIRED_OUTPUT = \"outputs\"\n",
    "\n",
    "with open (\"/data1/cosmos/Eric/kaggle/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
    "    character_map = json.load(f)\n",
    "rev_character_map = {j:i for i,j in character_map.items()}\n",
    "\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "\n",
    "if REQUIRED_SIGNATURE not in found_signatures:\n",
    "    raise KernelEvalException('Required input signature not found.')\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "output = prediction_fn(inputs=batch[0][0])\n",
    "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
    "print(prediction_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "openai.api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches = [batch for batch in test_ds]\n",
    "\n",
    "preds_list = []\n",
    "ground_truth_list = []\n",
    "\n",
    "for batch in batches[:1]:\n",
    "    source = batch[0]\n",
    "    target = batch[1].numpy()\n",
    "    bs = tf.shape(source)[0]\n",
    "    preds = model.generate(source, start_token_idx)\n",
    "    preds = preds.numpy()\n",
    "\n",
    "    for i in range(bs):\n",
    "        target_text = \"\".join([idx_to_char[_] for _ in target[i, :]])\n",
    "        ground_truth_list.append(target_text.replace('P', ''))\n",
    "        prediction = \"\"\n",
    "        for idx in preds[i, :]:\n",
    "            prediction += idx_to_char[idx]\n",
    "            if idx == end_token_idx:\n",
    "                break\n",
    "        preds_list.append(prediction)\n",
    "        input +=  \" | \" + preds_list[i]\n",
    "\n",
    "    api_response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Correct the Spelling for the following words/names/websites and then add | after each correctly spelled word:'\" + input + \"'\"}\n",
    "          ]\n",
    "        )\n",
    "    \n",
    "result_list = api_response['choices'][0]['message']['content'].split('|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <2398 massoni parks road>\n",
      "Post-Proccesing Prediction:  <2398 massoni parks road> \n",
      "Correct: <2398 masonic parks road>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <+34-63-74-92>\n",
      "Post-Proccesing Prediction:  <+34-63-74-92> \n",
      "Correct: <+34-63-74-92>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <thoale.com/artemb/ar-eraklaky>\n",
      "Post-Proccesing Prediction:  <thoale.com/artemb/ar-eraklaky> \n",
      "Correct: <tpmazembe/artist/kousek.lasky>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <540 odo 210th place>\n",
      "Post-Proccesing Prediction:  <540 odo 210th place> \n",
      "Correct: <540 south 310th place>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <+104-89-4958>\n",
      "Post-Proccesing Prediction:  <+104-89-4958> \n",
      "Correct: <+48-589-4958>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <joyana carlus stati>\n",
      "Post-Proccesing Prediction:  <joyana carlus stati> \n",
      "Correct: <jovan austin>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <www.xzs-kund/oderchercelom>\n",
      "Post-Proccesing Prediction:  <www.xzs-kund/oderchercelom> \n",
      "Correct: <www.azc-alphen.nl/motercycle/>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <+855-337-916-074>\n",
      "Post-Proccesing Prediction:  <+855-337-916-074> \n",
      "Correct: <+855-337-916-074>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <raceticar-matchas>\n",
      "Post-Proccesing Prediction:  <raceticar-matchas> \n",
      "Correct: <practicar-matcha>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: </condurbessaldrook>\n",
      "Post-Proccesing Prediction:  </condurbessaldrook> \n",
      "Correct: </cordes1344>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <mvalia-torumen-chin.com.au/>\n",
      "Post-Proccesing Prediction:  <mvalia-torumen-chin.com.au/> \n",
      "Correct: <valdy.ru/menguin-acquired/>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <2974 scoty carrson>\n",
      "Post-Proccesing Prediction:  <2974 scoty carrson> \n",
      "Correct: <2974 scotty carson>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <partoino-rusidence>\n",
      "Post-Proccesing Prediction:  <partoino-rusidence> \n",
      "Correct: <portofino-residence>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <www.eetablisean-eake.com>\n",
      "Post-Proccesing Prediction:  <www.eetablisean-eake.com> \n",
      "Correct: <www.etablisainteanne.com>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <www.brioradcararten.com/>\n",
      "Post-Proccesing Prediction:  <www.brioradcararten.com/> \n",
      "Correct: <www.devionhinton.com/>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <mames veitcherley>\n",
      "Post-Proccesing Prediction:  <mames veitcherley> \n",
      "Correct: <tom-veitch>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <ady574 barro drive>\n",
      "Post-Proccesing Prediction:  <ady574 barro drive> \n",
      "Correct: <857 baurkot drive>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <521 southeast 127th avenue>\n",
      "Post-Proccesing Prediction:  <521 southeast 127th avenue> \n",
      "Correct: <521 southeast 177th avenue>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <906586 seic plane>\n",
      "Post-Proccesing Prediction:  <906586 seic plane> \n",
      "Correct: <965860 leisore>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <lokuerciamiss.yde/iss-yomate23>\n",
      "Post-Proccesing Prediction:  <lokuerciamiss.yde/iss-yomate23> \n",
      "Correct: <lokerciamis.my.id/citymate235>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <shannd parralsi>\n",
      "Post-Proccesing Prediction:  <shannd parralsi> \n",
      "Correct: <kevin hurley>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <5829 farm harver road>\n",
      "Post-Proccesing Prediction:  <5829 farm harver road> \n",
      "Correct: <531859 arkhaven road>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <la-cecerda-drad>\n",
      "Post-Proccesing Prediction:  <la-cecerda-drad> \n",
      "Correct: <la-ciudad>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <1232 fort hie acest>\n",
      "Post-Proccesing Prediction:  <1232 fort hie acest> \n",
      "Correct: <163263 fort ritchie access>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <600-812-8126-81686>\n",
      "Post-Proccesing Prediction:  <600-812-8126-81686> \n",
      "Correct: <600-816-6767>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <www.cond-fake-ficendiesf/>\n",
      "Post-Proccesing Prediction:  <www.cond-fake-ficendiesf/> \n",
      "Correct: <www.commune-chihia.gov.tn>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: </ttp://www.carasaas-oudater/>\n",
      "Post-Proccesing Prediction:  </ttp://www.carasaas-oudater/> \n",
      "Correct: <https://www.casa.org.ar>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <jermaine eraimond>\n",
      "Post-Proccesing Prediction:  <jermaine eraimond> \n",
      "Correct: <jermaine raymond>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <793 moreshil>\n",
      "Post-Proccesing Prediction:  <793 moreshil> \n",
      "Correct: <793 mooreshill>\n",
      "\n",
      "~~~\n",
      "\n",
      "Prediction: <272-466-1121>\n",
      "Post-Proccesing Prediction:  <272-466-1121> \n",
      "Correct: <271-466-1311>\n",
      "\n",
      "~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\"Prediction: \" +preds_list[i])\n",
    "    print(\"Post-Proccesing Prediction: \" + result_list[i+1])\n",
    "    print(\"Correct: \" + ground_truth_list[i])\n",
    "    print('\\n~~~\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.5878378378378378\n"
     ]
    }
   ],
   "source": [
    "ground_truth_processed = [ground_truth_list[i][1:-1] for i in range(len(ground_truth_list))]\n",
    "preds_list_processed = [preds_list[i][1:-1] for i in range(len(preds_list))]\n",
    "lev_dist = [lev.distance(ground_truth_processed[i], preds_list_processed[i]) \n",
    "            for i in range(len(preds_list_processed))]\n",
    "N = [len(phrase) for phrase in ground_truth_processed]\n",
    "\n",
    "print('Validation score: '+str((np.sum(N) - np.sum(lev_dist))/np.sum(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
